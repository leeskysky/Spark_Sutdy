{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f540b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d22e8fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+------+---------+----------+--------+------+----------+--------+---------+\n",
      "|atcStep4Cd|        atcStep4CdNm|    clCdNm|diagYm|insupTpCd|msupUseAmt|recuClCd|sgguCd|  sgguCdNm|sidoCdNm|totUseQty|\n",
      "+----------+--------------------+----------+------+---------+----------+--------+------+----------+--------+---------+\n",
      "|     A02BX|Other drugs for p...|  종합병원|202203|        4|   5739020|      11|370600|    영천시|    경북|    58785|\n",
      "|     A02BX|Other drugs for p...|  종합병원|202203|        7|     11640|      11|370600|    영천시|    경북|      120|\n",
      "|     A02BX|Other drugs for p...|  종합병원|202203|        5|   1319212|      11|370600|    영천시|    경북|    12108|\n",
      "|     A02BX|Other drugs for p...|  종합병원|202203|        4|  69725606|      11|310603|수원팔달구|    경기|   503734|\n",
      "|     A02BX|Other drugs for p...|  종합병원|202203|        5|   7193639|      11|310603|수원팔달구|    경기|    46869|\n",
      "|     A02BX|Other drugs for p...|  종합병원|202203|        7|    335793|      11|310603|수원팔달구|    경기|     2664|\n",
      "|     A02BX|Other drugs for p...|    보건소|202203|        4|     17460|      71|230006|  대구중구|    대구|      180|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        4|    203633|      75|360003|    곡성군|    전남|     1991|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        5|    114262|      75|340014|    청양군|    충남|      725|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        4|    191158|      75|320012|    평창군|    강원|     1514|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        5|     26000|      75|320012|    평창군|    강원|      256|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        4|    343282|      75|350011|    장수군|    전북|     3420|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        5|      2163|      75|350011|    장수군|    전북|       21|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        7|     17460|      75|350011|    장수군|    전북|      180|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        4|    123480|      75|350010|    임실군|    전북|     1230|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        4|    170385|      75|320014|    화천군|    강원|     1074|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        5|      4760|      75|320014|    화천군|    강원|       28|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        4|    201796|      75|360006|    구례군|    전남|     1700|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        5|      2163|      75|360006|    구례군|    전남|       21|\n",
      "|     A02BX|Other drugs for p...|보건의료원|202203|        5|      5340|      75|370018|    울릉군|    경북|       60|\n",
      "+----------+--------------------+----------+------+---------+----------+--------+------+----------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "spark = SparkSession.builder.appName('MCB').getOrCreate()\n",
    "df = spark.read.csv(\"TEST.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "335734df",
   "metadata": {},
   "source": [
    "### 다중 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f2968acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# iris 데이터셋 로드\n",
    "iris = load_iris()\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder.appName(\"IrisExample\").getOrCreate()\n",
    "\n",
    "# iris 데이터셋을 Spark DataFrame으로 변환\n",
    "df_iris = spark.createDataFrame(\n",
    "    [(float(x[0]), float(x[1]), float(x[2]), float(x[3]), int(y)) \n",
    "     for x, y in zip(iris.data, iris.target)],\n",
    "    [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    ")\n",
    "\n",
    "# species 컬럼에서 versicolor인 행만 선택\n",
    "df_versicolor = df_iris.filter(col(\"species\") == 1)\n",
    "# df_versicolor.printSchema()\n",
    "\n",
    "# versicolor인 행과 나머지 행을 80:20 비율로 분리하여 train_data와 test_data로 생성\n",
    "train_data, test_data = df_versicolor.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# features 컬럼 생성\n",
    "assembler = VectorAssembler(inputCols=[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"], outputCol=\"features\")\n",
    "train_data = assembler.transform(train_data)\n",
    "test_data = assembler.transform(test_data)\n",
    "\n",
    "# Random Forest 모델 학습\n",
    "rf = RandomForestClassifier(labelCol=\"species\", featuresCol=\"features\")\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# # 다중 분류 평가자 생성 및 AUC 계산\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"species\", metricName=\"f1\")\n",
    "f1_score = evaluator.evaluate(predictions)\n",
    "print(\"F1-Score: {}\".format(f1_score))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"species\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "print(\"Precision: {}\".format(precision))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"species\", metricName=\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall: {}\".format(recall))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d26196d",
   "metadata": {},
   "source": [
    "### 이진분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "28b9d940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9523891966759004\n",
      "areaUnderROC: 0.9523891966759004\n",
      "areaUnderPR: 0.9686614406657555\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# breast_cancer 데이터셋 로드\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder.appName(\"BreastCancerExample\").getOrCreate()\n",
    "\n",
    "# breast_cancer 데이터셋을 Spark DataFrame으로 변환\n",
    "df_breast_cancer = spark.createDataFrame(\n",
    "    [(float(x[0]), float(x[1]), float(x[2]), float(x[3]), float(x[4]), \n",
    "      float(x[5]), float(x[6]), float(x[7]), float(x[8]), float(x[9]), \n",
    "      float(x[10]), float(x[11]), float(x[12]), float(x[13]), float(x[14]), \n",
    "      float(x[15]), float(x[16]), float(x[17]), float(x[18]), float(x[19]), \n",
    "      float(x[20]), float(x[21]), float(x[22]), float(x[23]), float(x[24]), \n",
    "      float(x[25]), float(x[26]), float(x[27]), float(x[28]), float(x[29]), int(y)) \n",
    "     for x, y in zip(breast_cancer.data, breast_cancer.target)],\n",
    "    [\"mean_radius\", \"mean_texture\", \"mean_perimeter\", \"mean_area\", \"mean_smoothness\", \n",
    "     \"mean_compactness\", \"mean_concavity\", \"mean_concave_points\", \"mean_symmetry\", \"mean_fractal_dimension\", \n",
    "     \"radius_error\", \"texture_error\", \"perimeter_error\", \"area_error\", \"smoothness_error\", \n",
    "     \"compactness_error\", \"concavity_error\", \"concave_points_error\", \"symmetry_error\", \"fractal_dimension_error\", \n",
    "     \"worst_radius\", \"worst_texture\", \"worst_perimeter\", \"worst_area\", \"worst_smoothness\", \n",
    "     \"worst_compactness\", \"worst_concavity\", \"worst_concave_points\", \"worst_symmetry\", \"worst_fractal_dimension\", \n",
    "     \"label\"]\n",
    ")\n",
    "\n",
    "# features 컬럼 생성\n",
    "assembler = VectorAssembler(inputCols=df_breast_cancer.columns[:-1], outputCol=\"features\")\n",
    "df_breast_cancer = assembler.transform(df_breast_cancer)\n",
    "\n",
    "# train_data, test_data 생성\n",
    "train_data, test_data = df_breast_cancer.randomSplit([0.8, 0.2], seed=1234)\n",
    "\n",
    "# Random Forest 모델 학습\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "model = rf.fit(train_data)\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# 이진 분류 평가자 생성 및 AUC 계산\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\")\n",
    "auc = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"AUC: {}\".format(auc))\n",
    "\n",
    "\n",
    "# 모델 학습 및 예측\n",
    "\n",
    "# 이진 분류 평가자 생성\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "# areaUnderROC 값 계산\n",
    "auc_roc = evaluator.evaluate(predictions)\n",
    "print(\"areaUnderROC: {}\".format(auc_roc))\n",
    "\n",
    "# 이진 분류 평가자 생성\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderPR\")\n",
    "\n",
    "# areaUnderPR 값 계산\n",
    "auc_pr = evaluator.evaluate(predictions)\n",
    "print(\"areaUnderPR: {}\".format(auc_pr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f2521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sky",
   "language": "python",
   "name": "conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
